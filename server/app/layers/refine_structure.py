from dotenv import load_dotenv
load_dotenv()
import logging
logger = logging.getLogger(__name__)
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")
async def refine_structure(content_description: str, initial_content: str, instructions: str) -> str:

    try:
        system = (
            "You are an assistant that refines and improves content generated by another LLM. "
            "Your task is to enhance the provided Markdown content by removing any unnecessary text, improving the structure, and adding more detailed content if needed. "
            "Use the content description as a guide to ensure the content aligns with the user's requirements."
            "Don't write anything except the content like no heres your refined content or no other messages."
            "Follow the instructions regarding the structure of the content or the content itself strictly."
        )

        human = ("Refine and improve the following Markdown content based on the given content description and instructions. "
                "Ensure the final content is detailed, well-structured, and adheres to the structural requests:\n\n"
                "Content Description:\n{description}\n\n"
                "Structural Instructions:\n{instructions}\n\n"
                "Initial Content:\n{content}")
        
        prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human)])
        chain = prompt |llm 
        response = await chain.ainvoke({"description": content_description, "content": initial_content, "instructions": instructions})
        refined_content = response.content.strip()

        # --- Minimal addition to print token usage ---
        print(response.usage_metadata)
        
        print("Running refine_structure")


        return refined_content

    except Exception as e:
        logger.error(f"Error in refine_structure: {str(e)}", exc_info=True)
        raise